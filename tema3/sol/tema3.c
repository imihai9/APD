// Mihai Ionescu, 335CA
// mpirun -np <numar_procese> ./tema3 <dimensiune_vector> <eroare_comunicatie>
#include "mpi.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define CNT_COORDS 3
#define INP_FILE_NAME_SIZE 13
#define min(x, y) (x < y) ? x : y

#define ARRAY_SEND_TAG 0
#define ARRAY_LEN_SEND_TAG 1

int num_procs, rank;
int *parents;
int *v, v_len;
int *v_recv, v_recv_len;

// Variables only used by coordinators )
int *coords, *c_cnt_workers, cnt_workers_total;

void print_topology(int rank) {
    printf("%d -> ", rank);

    short is_parent;

    for (int p = 0; ; p++) { // parent
        is_parent = 0;
        for (int w = 0; w < num_procs; w++) { // worker
            if (parents[w] == p) {
                if (!is_parent) {
                    is_parent = 1;
                    printf("%d:%d", p, w);
                } else {
                    printf(",%d", w);
                }
            }
        }

        if (!is_parent) {
            printf("\n");
            return;
        } else {
            printf(" ");
        }
    }
}

// COORDINATOR HELP FUNCTIONS -----------------------------------

void c_establish_topology(int *coords, int *c_cnt_workers) {
    int *parents_recv = (int*)malloc(num_procs * sizeof(int));
    memset(parents_recv, -1, num_procs * sizeof(int));

    for (int i = 0; i < CNT_COORDS; i++) {
        if (rank != coords[i]) {
            // Send own parent array (filled only with own wokers)
            // to the other coordinators
            MPI_Send(parents, num_procs, MPI_INT, coords[i], ARRAY_SEND_TAG, MPI_COMM_WORLD);
            printf("M(%d,%d)\n", rank, coords[i]); // log
        }
    }

    for (int i = 0; i < CNT_COORDS - 1; i++) {
      // Receive the corresponding array from the other coordinators
        MPI_Status status;
        MPI_Recv(parents_recv, num_procs, MPI_INT, MPI_ANY_SOURCE, ARRAY_SEND_TAG, MPI_COMM_WORLD, &status);
        for (int j = 0; j < num_procs; j++) {
            // Update local parents array with values received
            if (parents[j] == -1 && parents_recv[j] != -1) {
                parents[j] = parents_recv[j];
                c_cnt_workers[status.MPI_SOURCE]++;
            }
        }
    }
}

// (COORD 0) Divides and assigns array chunks to each coordinate
void assign_arr_to_coords (int *v, int v_len, int *c_cnt_workers, int *coords, int cnt_workers_total) {
    v = (int*)malloc(v_len *sizeof(int));
    for (int i = 0; i < v_len; i++)
        v[i] = i;

    // Start, end array v ids corresponding to each worker
    int id_start = 0;
    int id_end;
    for (int c_rank = 0; c_rank < CNT_COORDS; c_rank++) {
        id_end = id_start + c_cnt_workers[c_rank] - 1;

        int start = id_start * (double) v_len / cnt_workers_total;
        int end   = min((id_end + 1) * (double) v_len / cnt_workers_total, v_len);

        if (c_rank > 0) {
            MPI_Send(v + start, end - start, MPI_INT, coords[c_rank], ARRAY_SEND_TAG, MPI_COMM_WORLD);
            printf("M(%d,%d)\n", rank, coords[c_rank]); // log
        }
        else {
            v_recv_len = end - start;
            v_recv = (int*) malloc(v_recv_len * sizeof(int));
            memcpy(v_recv, v + start, (end - start) * sizeof(int));
        }

        id_start = id_end + 1;
    }
}


void c_recv_array_chunk(int **v_recv, int *v_recv_len, int v_total_len, int *c_cnt_workers, int cnt_workers_total) {
    // For each coordiantor - receive chunk of v generated by coord 0
    // Calculate length of v chunk
    int id_start = 0, id_end;

    for (int c_rank = 0; c_rank < rank; c_rank++)
        id_start += c_cnt_workers[c_rank];

    id_end = id_start + c_cnt_workers[rank] - 1;

    int start = id_start * (double) v_total_len / cnt_workers_total;
    int end   = min((id_end + 1) * (double) v_total_len / cnt_workers_total, v_total_len);

    *v_recv_len = end - start;
    *v_recv = (int*) malloc(*v_recv_len * sizeof(int));

    MPI_Status status;
    MPI_Recv(*v_recv, *v_recv_len, MPI_INT, 0, ARRAY_SEND_TAG, MPI_COMM_WORLD, &status);
}

// (ALL COORDS) Divides and assigns subarray chunks to each worker
void assign_arr_to_workers(int *v, int v_len, int cnt_workers) {
    int id = 0;
    for (int w_rank = 3; w_rank < num_procs; w_rank++) {    //TODO: 3 define
        if (parents[w_rank] == rank) {
            int start = id * (double) v_len / cnt_workers;
            int end   = min((id + 1) * (double) v_len / cnt_workers, v_len);
            int chunk_len = end - start;
            printf("CHUNK LEN %d\n", chunk_len);
            // Send array chunk length first
            MPI_Send(&chunk_len, 1, MPI_INT, w_rank, ARRAY_LEN_SEND_TAG, MPI_COMM_WORLD);
            printf("M(%d,%d)\n", rank, w_rank);
            // Send array chunk
            MPI_Send(v + start, chunk_len, MPI_INT, w_rank, ARRAY_SEND_TAG, MPI_COMM_WORLD);

            id++;
        }
    }
}

// MAIN COORDINATOR FUNCTIONS -----------------------------------
void exec_coordinator_part1(int v_len) {
    coords = malloc(CNT_COORDS * sizeof(int));
    for (int i = 0; i < CNT_COORDS; i++)
        coords[i] = i;

    int num_workers, *workers;
    c_cnt_workers = calloc (CNT_COORDS, sizeof(int)); // Number of workers that each coordinator has
    char file_name[INP_FILE_NAME_SIZE];

    // Read own workers from file
    sprintf(file_name, "%s%d%s", "cluster", rank, ".txt");
    
    FILE *in = fopen(file_name, "rt");
    fscanf(in, "%d", &num_workers);
    c_cnt_workers[rank] = num_workers;

    memset(parents, -1, num_procs * sizeof(int));
    workers = (int*)malloc(num_workers * sizeof(int));
    for (int i = 0; i < num_workers; i++) {
        fscanf(in, "%d", &workers[i]);
        parents[workers[i]] = rank;
    }

    c_establish_topology(coords, c_cnt_workers);
    
    cnt_workers_total = 0;
    for (int i = 0; i < CNT_COORDS; i++)
        cnt_workers_total += c_cnt_workers[i];

    // Coordinators now know the full topology.
    print_topology(rank);

    // Send parent array to own workers
    for (int i = 0; i < num_workers; i++) {
        MPI_Send(parents, num_procs, MPI_INT, workers[i], ARRAY_SEND_TAG, MPI_COMM_WORLD);
        printf("M(%d,%d)\n", rank, workers[i]); // log
    }
}

void exec_coordinator_part2 (int v_len) {
    if (rank == 0) {
        assign_arr_to_coords(v, v_len, c_cnt_workers, coords, cnt_workers_total);
    }
    else {
        c_recv_array_chunk(&v_recv, &v_recv_len, v_len, c_cnt_workers, cnt_workers_total);
    }

    printf("COORD%d: ", rank);
    for (int i = 0; i < v_recv_len; i++)
       printf("%d ", v_recv[i]);
    printf("\n");

    assign_arr_to_workers(v_recv, v_recv_len, c_cnt_workers[rank]);
}

// WORKER HELP FUNCTIONS ------------------------------
void w_recv_array_chunk() {
    MPI_Status status;
    // Receive array len;   parents[rank] == coordinator
    MPI_Recv(&v_len, 1, MPI_INT, parents[rank], ARRAY_LEN_SEND_TAG, MPI_COMM_WORLD, &status);
    v = (int*)malloc(v_len * sizeof(int));
    // Receive array
    MPI_Recv(v, v_len, MPI_INT, parents[rank], ARRAY_SEND_TAG, MPI_COMM_WORLD, &status);

    for (int i = 0; i < v_len; i++) {}
}

void w_compute() {
    for (int i = 0; i < v_len; i++)
        v[i] *= 2;
}

// Send array result (after computation) to coordinator
void w_send_array_result() {
    MPI_Send(v, v_len, MPI_INT, parents[rank], ARRAY_SEND_TAG, MPI_COMM_WORLD);
    printf("M(%d,%d)\n", rank, parents[rank]);
}

// MAIN WORKER FUNCTIONS ------------------------------
void exec_worker_part1() {
    int coord; // coordinator

    // Receive parent array from coordinator
    MPI_Status status;
    MPI_Recv(parents, num_procs, MPI_INT, MPI_ANY_SOURCE, 0, MPI_COMM_WORLD, &status);

    coord = parents[rank]; // same as status.MPI_SOURCE;
    print_topology(rank);
}

void exec_worker_part2() {
    w_recv_array_chunk();
    w_compute();
    w_send_array_result();
}

int main (int argc, char *argv[]) {
    MPI_Init(&argc, &argv);
    MPI_Comm_size(MPI_COMM_WORLD, &num_procs); // Total number of processes.
    MPI_Comm_rank(MPI_COMM_WORLD,&rank);       // The current process ID / Rank.

    int v_len = atoi(argv[1]);

    parents = (int*)malloc(num_procs * sizeof(int));

    if (rank < CNT_COORDS)
        exec_coordinator_part1(v_len);
    else
        exec_worker_part1();

    MPI_Barrier(MPI_COMM_WORLD);

    if (rank < CNT_COORDS)
        exec_coordinator_part2(v_len);
    else
        exec_worker_part2();

    MPI_Finalize();
    return 0;
}
